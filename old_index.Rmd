---
title: "Vulfpeck"
author: "Levi Knigge"
date: "10-2-2021"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: flatly
    css: styles.css
    orientation: rows
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE, cache = TRUE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, include=FALSE}
library(tibble)
library(tidyverse)
library(spotifyr)
library(gridExtra)
library(flexdashboard)
library(readr)
library(leaflet)
library(DT)
library(lubridate)
library(plotly)
library(gridExtra)
library(grid)
library(ggplot2)
library(lattice)
library(compmus)

```

```{r}
vulfpeck <- get_playlist_audio_features("", "3nI3zFZc0zNawgGGBvlLjd")
corywong <- get_playlist_audio_features("", "63WEX3nqvVWQM08k4GOdpY")
katzman <- get_playlist_audio_features("", "26kcyNqQKAN3fnuO8NCL4B")
fearless <- get_playlist_audio_features("", "67Zq8kPS6CmIcBZYEIy5JL")
nate <- get_playlist_audio_features("", "3PcaerIEOjHbo56TmnR62I")
nate <- nate[!is.na(nate$playlist_id),]
woody <- get_playlist_audio_features("", "1YNoeB7YRKmwXDwxL6kXHv")


# summary(vulfpeck)

artists <-
  bind_rows(
    vulfpeck %>% mutate(category = "Vulfpeck"),
    corywong %>% mutate(category = "Cory Wong"),
    katzman %>% mutate(category = "Katzman"),
    fearless %>% mutate(category= "Fearless"),
    woody %>% mutate(category = "Woody"),
    nate %>% mutate(category = "Nate")
  )

artists <- artists %>% mutate(artist_track = paste(category, track.name))

```

```{r cars}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(5.0, 2.0, 3.5, 2.0, 4.5, 4.0, 2.0, 4.5, 2.0, 3.5, 1.5, 4.0)
minor_key <-
  c(5.0, 2.0, 3.5, 4.5, 2.0, 4.0, 2.0, 4.5, 3.5, 2.0, 1.5, 4.0)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

Predicting {.storyboard}
========================================================================

### TESTING
```{r, results = 'hide'}
library(tidyverse)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(spotifyr)
library(compmus)

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  

vulf_features <-
  artists %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    category = factor(category),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))

```
```{r}
vulf_recipe <-
  recipe(
    category ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = vulf_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].

vulf_recipe2 <-
  recipe(
    category ~
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c11,
    data = vulf_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].
```
```{r}
vulf_cv <- vulf_features %>% vfold_cv(5)
```
```{r}
knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
vulf_knn <- 
  workflow() %>% 
  add_recipe(vulf_recipe2) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    vulf_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```
```{r}
vulf_knn %>% get_conf_mat()
```
```{r}
#vulf_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
```
```{r}
vulf_knn %>% get_conf_mat() %>% autoplot(type = "heatmap")
```
```{r}
#vulf_knn %>% get_pr()
```

***

When constructing the KNN network one thing that drastically improved performance is using only the top 10 most influential features. Still there are some interesting observations to be made. Although this confusion matrix gives some insight, it is skewed towards the bigger categories like Vulfpeck and Cory wong, and it only shows numbers, and not a clear measure of performance.

### Detailed analysis of performance

```{r}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
vulf_forest <- 
  workflow() %>% 
  add_recipe(vulf_recipe2) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    vulf_cv, 
    control = control_resamples(save_pred = TRUE)
  )


```
```{r}
vulf_forest %>% get_conf_mat() %>% autoplot(type = "heatmap")
```
```{r}
vulf_forest %>% get_pr()
```
***

As with the KNN network we see in this Random Forest implementation the Fearless Flyers playlist is the most distinctive group in the corpus. 

### Importance of features

```{r}
workflow() %>% 
  add_recipe(vulf_recipe) %>% 
  add_model(forest_model) %>% 
  fit(vulf_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")
```

***

This shows the most important distinguishing features between the different playlists. Loudness seems to be the key distinguishing feature, followed by instrumentalness and energy. The rest of the top 10 is mainly timbre components, while the key of the song doesn't seem to contribute all that much to the predictions.

### Clustering

```{r}
clustering <-
  artists %>%
  add_audio_analysis() %>%
  mutate(
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean"
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```
```{r}
cluster_juice <-
  recipe(
    artist_track ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = clustering
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors()) %>% 
#  step_range(all_predictors()) %>% 
  prep(clustering %>% mutate(artist_track = str_trunc(artist_track, 60))) %>%
  juice() %>%
  column_to_rownames("artist_track")

library(rpart)
library(factoextra)

# vulf_means = kmeans(cluster_juice, 6, iter.max = 100, nstart = 25)

#km.res <- kmeans(iris.scaled, 3, nstart = 10)

# Visualize kmeans clustering
# use repel = TRUE to avoid overplotting


res.km <- eclust(cluster_juice, k=6, "kmeans", nstart = 25, graph=FALSE)

fviz_cluster(res.km, clutser_juice, ellipse.type = "norm",  repel=TRUE, labelsize = 9, , ellipse.level=.7)

```
```{r}
results <- res.km[1]$cluster

test <- data.frame(matrix(0, ncol = 6, nrow = 6))

names(test) <- c('Vulfpeck', 'Cory', 'Theo', 'Fearless','Woody', 'Nate')
length(results)
for (i in 1:length(results)) {
  if (i < 75) {
    test$Vulfpeck[results[[i]]] <- test$Vulfpeck[results[[i]]]+1
  }
  else if (i < 123) {
      test$Cory[results[[i]]] <- test$Cory[results[[i]]]+1
  }
  else if (i < 154) {
    test$Theo[results[[i]]] <- test$Theo[results[[i]]]+1
  }
  else if (i < 176) {
    test$Fearless[results[[i]]] <- test$Fearless[results[[i]]]+1
  }
  else if (i < 200) {
    test$Woody[results[[i]]] <- test$Woody[results[[i]]]+1
  }
  else  {
    test$Nate[results[[i]]] <- test$Nate[results[[i]]]+1
  }
}

test

library(reshape2)
test <- melt(test)  #the function melt reshapes it from wide to long
test$rowid <- 1:6

ggplot(test, aes(variable, value, fill = variable)) +
  geom_col() +
  facet_wrap(~ rowid) + 
  scale_colour_hue("clarity") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```
```{r}
df = data.frame(matrix(data=c(1,3,1,2,3,1,2,3,2,3,1,2,3,1,2,3,
                              1,3,2,1,2,2,2,3,3,3,1,1,1,3,3,2), 
                       ncol=2,byrow=TRUE))
dimnames(df)[[2]] =c("x","y")

dodgebars <- 
  ggplot(data = df,aes(factor(y),fill=factor(x))) +
  geom_bar(aes(group=factor(x)),
           position="dodge")
facetedbars <- 
  ggplot(data = df, aes(factor(y))) +
  geom_bar(aes(group=x)) +
  facet_grid(~x)
dodgebars
facetedbars
```

***

Here we try clustering in the 6 categories we defined at the beginning of this portfolio. As you can see the groups are certainly not pure. Nate smith seems to concentrate in the upper right, but is also in the lower clusters. I will analyse the exact classifications more precisely in the final portfolio.

### Principal Components

```{r}
library(FactoMineR)
pca <- PCA(cluster_juice, ncp=6, scale.unit = TRUE, graph=FALSE)
#get_eigenvalue(pca)
#fviz_eig(pca, addlabels=TRUE)
#pcavar <- get_pca_var(pca)
fviz_pca_var(pca, col.var="cos2", alpha.var="contrib", gradient.cols = c("blue", "green", "red"), repel = TRUE)
```

***

In the previous slide we were shown the 6 clusters our random forest came up with. This is represented in our graph along two dimensions. In machine learning Principal Component Analysis is used to determine a linear combination of the features in our dataset that offer the highest rate of variability. In this circle we see the same two dimensions, but now plotted on top is the contribution of each of our features, the ones we know how to interpret. We can see that acousticness and energy are the biggest contributours for dimension 1, while c01 plays the largest role in dimension two. 

Tempo {.storyboard}
========================================================================

### TESTING

```{r}

hist1 <- ggplot(data = artists, mapping = aes(x = tempo)) + 
  geom_histogram(aes(fill = category)) +
  theme_light() +
  ggtitle("Tempos") +
  theme(legend.position="none")

hist1

hist3 <- ggplot(data = artists, mapping = aes(x = tempo, y = category, fill = category)) + 
  geom_violin(scale = "area", width=1, trim=FALSE, adjust = .25) +
#  geom_density(adjust=0.2) +
#  facet_wrap(~ category) +
#  geom_jitter(height = 0.1, width = 0) +
#  geom_boxplot(width=0.1, color="white") +
  stat_summary(fun.x=median, geom="point", size=2, color="red") +
  scale_x_continuous() +
  theme_light() +
  ggtitle("Tempo")

hist3

# test1 <- artists %>%
#   mutate(trends = ifelse(trend == "dance", "dance", "other")) %>%
#   filter(trends == "dance")%>%
#     count(key_name) %>%
#       mutate(perc = n/sum(n), trends = "dance")
#   
# other_counts <- corpus %>%
#   mutate(trends = ifelse(trend == "dance", "dance", "other")) %>%
#   filter(trends == "other")%>%
#     count(key_name) %>%
#       mutate(perc = n/sum(n), trends = "other")

# rbind(dance_counts, other_counts) %>%
#   ggplot(aes(x = key_name, y = perc)) +
#     geom_bar(stat = "identity", fill = "skyblue") + 
#       facet_wrap(~trends)+
#         labs(title = "Distribution of keys in the corpus",
#              x = "Key",
#              y = "Normalised Frequency")
```


### Nate Smith's Get Down

```{r, cache=TRUE}
get_down <- get_tidy_audio_analysis("6bZ68VCNVyuKyE534TcmsW")
adrienne <- get_tidy_audio_analysis("66xEqq3jsr3p52uOhGM5Nm")
five <- get_tidy_audio_analysis("5T5W7UzmLJljQUIJ7FxotZ")
paved <- get_tidy_audio_analysis("3NxejBP3DtRZ55y2MQHShk")

# spotify:track:3NxejBP3DtRZ55y2MQHShk - paved
#spotify:track:5T5W7UzmLJljQUIJ7FxotZ - big/little five
# spotify:track:66xEqq3jsr3p52uOhGM5Nm - adrienne

get_down %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()




```

***

A tempogram of Nate Smith's shows his impeccable timing and ability to play with tempo.

### Nate Smith playing with time


```{r}
five %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

paved %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

***

Nate Smith's incredible drumming

Nate Smith is a legendary drummer, and one of his strengths is his impeccable timing. As you can see in these plots the tempo of the song is straight as an arrow. As for Big/small Five, the song is in 5/4, but one of Nate Smith's signature moves is playing a 4 beat rythm over 5/4 and keeping the timing perfect. Being used to western music you expect the song to change in an even number of measures, but because the song is in 5/4 and the change in the song happens after 7 measures you are completely blindsided. Not only does it not line up with the 4/4, but even in 5/4 the change seems one measure early.

You can also clearly see spotify struggles with his playing different feeling rythms over the same tempo. In the end of "paved" you can clearly see he slows down as a means to end the song.

### Adrienne & Adrianne


```{r}
adrienne %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

***

Vulfpeck and Fearless flyer's adrienne

There seem to be two rythms in this song. This is most likely caused by the clear 4/4 feel of the drums in comparison with the offset melody. The melody of the chorus starts on the off-beat of the first beat of the bar of the drums. The melody covers 2 and a half bars, resulting in a sort of 5/8 feel to the song. Due to the fact that the chorus ends on a rest that goes over the first beat of the verse this doesn't make either tempo stand out as more likely.


<!-- Test -->
<!-- ======================================================================= -->


<!-- Column {.sidebar} -->
<!-- -------------------------------------------------------- -->

<!-- ### Testing -->

<!-- testing -->

<!-- Column {} -->
<!-- ------------------------------------------------------- -->

<!-- ```{r} -->
<!-- get_down_2 <- -->
<!--   get_tidy_audio_analysis("6bZ68VCNVyuKyE534TcmsW") %>% -->
<!--   select(segments) %>% -->
<!--   unnest -->

<!-- get_down_2 %>% -->
<!--   mutate(loudness_max_time = start + loudness_max_time) %>% -->
<!--   arrange(loudness_max_time) %>% -->
<!--   mutate(delta_loudness = loudness_max - lag(loudness_max)) %>% -->
<!--   ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) + -->
<!--   geom_line() + -->
<!--   xlim(0, 30) + -->
<!--   theme_minimal() + -->
<!--   labs(x = "Time (s)", y = "Novelty") -->
<!-- ``` -->

Chords and Keys{.storyboard}
=======================================================================

### Theo Katzman's chords- You could be president by Theo Katzman   

```{r}
twenty_five <-
  get_tidy_audio_analysis("1aEcZKCwqln3s3VvY5Kwxl") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
twenty_five %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***

Here we see the chordogram for "You could be president" by Theo Katzman. A typical song in his style. It has a halftime beat and vocals, a repeating guitar riff as a melody and a more uptempo chorus. It also has a typical piano and guitar solo at 135 seconds. We can see clearly he sticks to the E flat 7 chord that the song is built on througout the entire song.

### Cory Wong Chordogram - Golden


```{r}
cory_golden <-
  get_tidy_audio_analysis("7wjmwD5nIYWVnHiR3X3PTO") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```

```{r}
cory_golden %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```

***

Cory wong's golden is very uptempo song, which is not something very typical for him. The song also features a vocal performance that is similar to a pop song. Coincidentally this song also sticks to E flat 7 as a main chord, but you can see this is not the only chord used. This is probably because of the harmonies between different instruments in this song.


Chromatic and Cepstral Analysis {.storyboard}
=======================================================================

### Cepstograms of Cory Wong by Vulfpeck (featuring Cory Wong)

```{r, fig.width = 16, fig.height=9}
corysong1 <-  get_tidy_audio_analysis("1L9qsoNnyT3r8fgr2Pr7Ty")%>% # Change URI.
  compmus_align(sections, segments) %>%                     # Change `bars`
  select(sections) %>%                                      #   in all three
  unnest(sections) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

corysong2 <-  get_tidy_audio_analysis("1L9qsoNnyT3r8fgr2Pr7Ty")%>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

corysong3 <-  get_tidy_audio_analysis("1L9qsoNnyT3r8fgr2Pr7Ty")%>% # Change URI.
  compmus_align(beats, segments) %>%                     # Change `bars`
  select(beats) %>%                                      #   in all three
  unnest(beats) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

corysong4 <-  get_tidy_audio_analysis("1L9qsoNnyT3r8fgr2Pr7Ty")%>% # Change URI.
  compmus_align(tatums, segments) %>%                     # Change `bars`
  select(tatums) %>%                                      #   in all three
  unnest(tatums) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )


tl <- corysong1 %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() + 
  theme(legend.position = "none",
        rect = element_rect(fill = "transparent"))

tr <- corysong2 %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() + 
  theme(legend.position = "none",
        rect = element_rect(fill = "transparent"))

bl <- corysong3 %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() +
  theme(legend.position = "none",
        rect = element_rect(fill = "transparent"))

br <- corysong4 %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +                              
  theme_classic() + 
  theme(legend.position = "none",
        rect = element_rect(fill = "transparent"))

grid.arrange(tl, tr, bl, br, ncol=2)



```

***

We learn more about the song every time we increase the resolution of the graph. You can clearly see the end of the song has high values for the third cepstral component, which corresponds to the outro which features a live audience cheering.

Another striking part is the difference around the 100 second mark, before it the song has high values for cepstral features 2-4, while afterwards component 1 is the most prominent. The one thing that is clearly missing in the second part are high pitches on guitar. The bass and drums stop around the 90 second mark, but later return although less prominently.

In the first part we also see interesting patterns arise in the more detailed resolutions. Closer investigation will be done to explain these.

### Here we see the Self Similarity Matrix for "Too hot in LA"

```{r, fig.width = 12, fig.height=6}

#knitr::opts_chunk$set(fig.height = 9, fig.width = 7)

#knitr::opts_chunk$set(out.height = "\\textheight",  out.width = "\\textwidth")

toohot1 <-  get_tidy_audio_analysis("2IB1LWbNli57u0k7U1GAXt")%>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

l <- toohot1 %>%
  compmus_self_similarity(timbre, "angular") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")

r <- toohot1 %>%
  compmus_self_similarity(pitches, "angular") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
grid.arrange(l,r, ncol=2)
```

***

When analyzing the structure of the self similarity matrix for timbre(left) and pitch(right) there are some clear structures. The song has a clear pre-chorus and chorus. What is interesting is that the most prominent yellow pitch lines are only for the prechorus, meaning the chorus and verse are very similar in pitch. The main melody is provided by the bass, and indeed the bass part is the same for the chorus and verses, and different for the prechorus.    


Introduction
=========================================================================

```{r, echo=FALSE}
# Define variable containing url
url <- "https://media.ticketmaster.com/tm/en-us/dam/a/b1f/f8c61ced-7670-4495-8a8f-15b66cf9db1f_247161_CUSTOM.jpg"
```
<center><img src="`r url`"></center>

::: {.center data-latex=""}
This portfolio explores the albums and singles of Vulfpeck and their members and closely associated acts Theo Katzmann and Woody Goss and collaborative acts Joey Dosik and Cory Wong. Vulfpeck’s Joe Dart is praised as one of the best bassists to emerge in recent years, but that’s not the only reason for this choice. Firstly, Vulfpeck is known for their one-take style of recording and off-beat musical style. Secondly, the band has a few closely associated members that appear on a large section of their music. Finally, the band’s members have their own solo projects which often still feature each other. This allows us to compare the albums of these artists and see what makes their music unique.


The natural groups are the main artist on each album. Though they share a band there are some clear differences in genre, Vulfpeck is primarily funk, Theo Katzman is more slow love songs, Cory Wong has the danceability of pop music.


The albums and singles are a good representation of the artists. They all use Spotify as their primary way of distribution and have at least an album each.


Typical tracks for Vulfpeck are Cory Wong (yes that song is named after another artist in the list, it’s going to be confusing data!) or It Gets Funkier, the latter having the typical funk structure and interaction between instruments. An atypical song would be Theo Katzman’s As the Romans do. Whereas his solo music often has a halftime feel soulful style, this is an up-tempo track, more like what I would personally expect to come from Cory Wong’s repertoire. 


It will be interesting to find out what makes each artists music truly theirs, even though they are so closely related and collaborative.
:::



Data Exploration
=========================================================================






Column {.sidebar}
--------------------------------------------------------

### Distribution of Valence 

To start off, we load the playlists containing each artists albums into its own variable, and create a combined dataframe using category as the dividing variable between the different artists. Now we can begin making some exploratory plots.

The first thing I was eager to find out is to see how accurate my own interpretation of each artists music was. One feature I could see making a clear division between artists was valence. I expected Cory Wong's music to be high in valence, because of it's positive and high energy feeling, Vulfpecks valence to be hard to grasp, and the same for Woody Goss. Their music has a very fun experimental quality but is modest in the musical expression of this enjoyment, it's not over the top happy-clappy music. Theo Katzman's music is more romantic, I would expect this to be an average valence, as it contains both the ups and downs of love.

Column {}
---------------------------------------------------

### Valence by artistS

```{r}

test <- ggplot(artists, aes(valence, ..density.., color=category)) +
  geom_histogram(bins=20, alpha=0.5) +
  facet_wrap(~ category) +
  theme(axis.text.y = element_blank())
test
```

> To my surprise, Cory Wong was shown to be the most 'negative' out of all four artists. 

### Tempo vs Dancability {data-padding=100}

```{r}
advanced <- artists %>%                    # Start with awards.
  mutate(
    mode = ifelse(mode == 0, "Minor", "Major")
  ) %>%
  ggplot(                     # Set up the plot.
    aes(
      x = tempo,
      y = danceability,
#      size = liveness,
      colour = mode
    )
  ) +
  geom_point(alpha = 0.5) +
  facet_wrap(~category) +
  scale_colour_brewer(        # Use the Color Brewer to choose a palette.
    type = "qual",            # Qualitative set.
    palette = "Set1"        # Name of the palette is 'Paired'.
  ) +             # Use a simpler theme.
  labs(                       # Make the titles nice.
    x = "Tempo",
    y = "Danceability",
    colour = "Mode"
  )
advanced
```

***

To see where this difference is coming from I looked at some more low-level features such as tempo and mode. This plot gives a good interpretation of some of the differences between the artists.



It Gets Funkier {.storyboard}
=================================================

### It Gets Funkier
```{r}

fig <- function(width, heigth){
     options(repr.plot.width = width, repr.plot.height = heigth)
}
funky1 <-
  get_tidy_audio_analysis("0vOAN45nUNSqRIWPTOSDsJ") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

funky2 <-
  get_tidy_audio_analysis("33BRNcBN01BsjKkAxlFYI4") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

funky3 <-
  get_tidy_audio_analysis("7IMHomgWWQAxCueJX8DKFi") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

funky4 <-
  get_tidy_audio_analysis("2eNKE4PW5uL0pIfGNw01SV") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

funky1 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  xlim(12, 30)

```

***

Description


### It Gets Funkier II

```{r}
fig(10,4)
funky2 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  xlim(9, 30)




```


### It Gets Funkier III


```{r}
funky3 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  xlim(11, 30)

```


### It Gets Funkier IV


```{r}
funky4 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c() +
  xlim(10, 20)

```

### Frame 5

```{r}
tl <- compmus_long_distance(
  funky1 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  funky1 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  feature = pitches,
  method = "manhattan"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "I", y = "II") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

tr <- compmus_long_distance(
  funky1 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  funky3 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  feature = pitches,
  method = "manhattan"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "I", y = "III") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

bl <- compmus_long_distance(
  funky2 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  funky3 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  feature = pitches,
  method = "manhattan"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "II", y = "III") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

br <- compmus_long_distance(
  funky3 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  funky4 %>% mutate(pitches = map(pitches, compmus_normalise, "manhattan")),
  feature = pitches,
  method = "manhattan"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "III", y = "IV") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)

grid.arrange(tl, tr, bl, br, ncol=2)


```

*** 
  
Description

Here we compare the different versions of It Gets Funkier.

Despite their seeming similarity, I could not get the dynamic time-warping to show that result clearly.
